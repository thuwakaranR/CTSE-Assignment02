{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2af02ba1",
   "metadata": {},
   "source": [
    "# CTSE Lecture Notes Chatbot using LangChain + HuggingFace\n",
    "This notebook demonstrates a simple chatbot that answers questions based on CTSE lecture notes using a Retrieval-Augmented Generation (RAG) approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d77a65f",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-huggingface chromadb transformers unstructured sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500650f8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings, HuggingFacePipeline\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "201bfe6c",
   "metadata": {},
   "source": [
    "# Step 1: Load the Lecture Notes PDF\n",
    "We'll use LangChain's `PyPDFLoader` to extract text from the CTSE lecture notes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca902fb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 966 pages\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader(\"data/ctse_notes.pdf\")\n",
    "documents = loader.load()\n",
    "print(f\"Loaded {len(documents)} pages\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cd76fe",
   "metadata": {},
   "source": [
    "# Step 2: Split Documents into Chunks\n",
    "We use `RecursiveCharacterTextSplitter` to chunk the content into overlapping sections.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1746709b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total chunks created: 2018\n"
     ]
    }
   ],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "print(f\"Total chunks created: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3812fb",
   "metadata": {},
   "source": [
    "# Step 3: Generate Embeddings\n",
    "We'll use HuggingFace Sentence Transformers for vector representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea927201",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e3cae08",
   "metadata": {},
   "source": [
    "# Step 4: Store Chunks in Chroma Vector DB\n",
    "We'll persist the chunks and embeddings to local vector storage.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0f91d6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "persist_directory = \"./ctse_db\"\n",
    "vectordb = Chroma.from_documents(documents=docs, embedding=embedding_model, persist_directory=persist_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacb4824",
   "metadata": {},
   "source": [
    "# Step 5: Load a Local LLM (FLAN-T5)\n",
    "We'll use HuggingFace's pipeline for open-source inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f96a17",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "hf_pipeline = pipeline(\n",
    "    \"text2text-generation\",\n",
    "    model=\"google/flan-t5-base\",\n",
    "    tokenizer=\"google/flan-t5-base\",\n",
    "    max_length=512,\n",
    "    do_sample=False\n",
    ")\n",
    "llm = HuggingFacePipeline(pipeline=hf_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af863e87",
   "metadata": {},
   "source": [
    "# Step 6: Setup the QA Chain\n",
    "Combining retriever and LLM using LangChain's RetrievalQA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f97e082",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "retriever = vectordb.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "qa_chain = RetrievalQA.from_chain_type(llm=llm, retriever=retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11f6a97",
   "metadata": {},
   "source": [
    "# Step 7: Ask Questions (Notebook-Friendly)\n",
    "You can ask any question based on the CTSE lecture notes.  \n",
    "Type `'exit'` to end the interaction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217d42ec",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Interactive question loop (Jupyter Notebook friendly)\n",
    "def interactive_ctse_bot():\n",
    "    while True:\n",
    "        query = input(\"\\nAsk a question (or type 'exit' to quit): \")\n",
    "        if query.lower().strip() == \"exit\":\n",
    "            print(\"Exiting the chatbot session.\")\n",
    "            break\n",
    "        answer = qa_chain.invoke({\"query\": query})\n",
    "        print(\"Answer:\", answer[\"result\"])\n",
    "\n",
    "# Call this function to start Q&A\n",
    "interactive_ctse_bot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
